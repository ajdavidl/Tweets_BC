{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Bert Neuralmind foi o melhor modelo nos dados de treinamento.\n",
    "\n",
    "Este caderno treina o Bert Neuralmind em todos os tweets para criar o modelo final de classificação da dissertação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3OBmC3UmYaRP"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVCytM2-YWWR"
   },
   "outputs": [],
   "source": [
    "source_folder = 'dados'\n",
    "destination_folder = 'dados\\model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO = \"bert-base-multilingual-cased\"\n",
    "MODELO = 'neuralmind/bert-base-portuguese-cased'\n",
    "Nr_epochs = 10\n",
    "lr = 2e-5\n",
    "nome_modelo = MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EyZ65LZ8YgtG"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dl7rqQ4uZPiv"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# Preliminaries\n",
    "\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, cohen_kappa_score, balanced_accuracy_score, roc_auc_score, recall_score, precision_score\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RDBAx2Q-ZMl7",
    "outputId": "e8a2eac3-3e34-48bf-8df6-6fe870fbbd01"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqOJAYCiYlZs"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fF1DCVrCh6_d"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODELO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "fdGccqrAZYjw",
    "outputId": "40c9d8a8-0c04-4759-e05e-bbd78f145d2b"
   },
   "outputs": [],
   "source": [
    "# Model parameter\n",
    "MAX_SEQ_LEN = 128\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
    "fields = [('texto', text_field), ('label', label_field) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('dados\\\\df_processado.pkl')\n",
    "df.info()\n",
    "#df = df[df['sent_manual'].fillna('nan').str.contains('N|E|S|C|D')]\n",
    "df2 = df[df['sent_manual'].fillna('nan').str.contains('N|E|S|C')].copy()\n",
    "#df[df['sent_manual'].str.contains('S|D')]['sent_manual'] = 'N'\n",
    "def corrige_label(label):\n",
    "    if label == 'S' or label == 'E':\n",
    "        return('N')\n",
    "    else:\n",
    "        return(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df['data']>\"2010-01-01\"]\n",
    "df = df[~df['sent_manual'].isin(['D'])] #remove tweets marcadaos com D (delete)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['sent_manual'] = df2['sent_manual'].apply(corrige_label)\n",
    "df2['sent_manual'].value_counts()\n",
    "lista_index = df2.index.values.copy()\n",
    "lista_texto = df2.tweet_limpo.to_list().copy()\n",
    "lista_label = df2.sent_manual.to_list().copy()\n",
    "\n",
    "#TRANSFORMA PARA CAIXA BAIXA\n",
    "corpus = lista_texto.copy()\n",
    "#for i in range(0,len(corpus)):\n",
    "#    corpus[i]=corpus[i].lower()\n",
    "\n",
    "\n",
    "#REMOVE NUMEROS E PONTUACAO\n",
    "for i in range(0,len(corpus)):\n",
    "    corpus[i] = re.sub('[0-9]+', '', corpus[i])\n",
    "    corpus[i] = re.sub(r'[^\\w\\s]','',corpus[i])\n",
    "    corpus[i] = re.sub('º','',corpus[i])\n",
    "\n",
    "# create a dataframe using texts and lables\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = corpus\n",
    "#trainDF['text'] = lista_texto\n",
    "trainDF['label'] = lista_label\n",
    "\n",
    "\n",
    "\n",
    "trainDF['label'] = trainDF['label'].apply(lambda x: 0 if x=='N' else 1)\n",
    "\n",
    "trainDF['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset\n",
    "test_size=0.30\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'], test_size=0.4, random_state = 100)\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "        'texto' : train_x,\n",
    "        'label' : train_y\n",
    "        })\n",
    "\n",
    "df_valid = pd.DataFrame({\n",
    "        'texto' : valid_x,\n",
    "        'label' : valid_y\n",
    "        })\n",
    "\n",
    "\n",
    "valid_x, test_x, valid_y, test_y = model_selection.train_test_split(df_valid['texto'], df_valid['label'], test_size=0.5, random_state = 100)\n",
    "\n",
    "df_valid = pd.DataFrame({\n",
    "        'texto' : valid_x,\n",
    "        'label' : valid_y\n",
    "        })\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "        'texto' : test_x,\n",
    "        'label' : test_y\n",
    "        })\n",
    "\n",
    "df_total = pd.DataFrame({\n",
    "    'texto' : df.tweet_limpo.to_list(),\n",
    "    'label' : np.ones(df.shape[0]).tolist()\n",
    "})\n",
    "\n",
    "df_train.to_csv(source_folder+\"\\\\trainBert.csv\", index = False)\n",
    "df_valid.to_csv(source_folder+\"\\\\validBert.csv\", index = False)\n",
    "df_test.to_csv(source_folder+\"\\\\testBert.csv\", index = False)\n",
    "df_total.to_csv(source_folder+\"\\\\totalBert.csv\", index = False)\n",
    "\n",
    "\n",
    "print(\"df_train.shape =\", df_train.shape)\n",
    "print(\"df_valid.shape =\", df_valid.shape)\n",
    "print(\"df_test.shape =\", df_test.shape)\n",
    "print(\"df_total.shape =\", df_total.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "fdGccqrAZYjw",
    "outputId": "40c9d8a8-0c04-4759-e05e-bbd78f145d2b"
   },
   "outputs": [],
   "source": [
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='trainBert.csv', validation='validBert.csv',\n",
    "                                           test='totalBert.csv', format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.texto),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=16, sort_key=lambda x: len(x.texto),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "test_iter = Iterator(test, batch_size=16, device=device, train=False, shuffle=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RkcXCHSph1_"
   },
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        options_name = MODELO\n",
    "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
    "\n",
    "    def forward(self, text, label):\n",
    "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
    "\n",
    "        return loss, text_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(load_path, model):\n",
    "    \n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFBhAW6rwKly"
   },
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (texto, label), _ in test_loader:\n",
    "\n",
    "                label = label.type(torch.LongTensor)           \n",
    "                label = label.to(device)\n",
    "                texto = texto.type(torch.LongTensor)  \n",
    "                texto = texto.to(device)\n",
    "                output = model(texto, label)\n",
    "\n",
    "                _, output = output\n",
    "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "                y_true.extend(label.tolist())\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "RLlijSLcxv2j",
    "outputId": "e301fd54-912a-4b75-fd8f-c79379d2a008"
   },
   "outputs": [],
   "source": [
    "best_model = BERT().to(device)\n",
    "\n",
    "load_checkpoint(destination_folder + '\\\\model.pt', best_model)\n",
    "\n",
    "y_pred = evaluate(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BERT_neuralmind'] = y_pred\n",
    "df['BERT_neuralmind'] = df['BERT_neuralmind'].apply(lambda x: \"C\" if x==1 else \"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['BERT_neuralmind'].value_counts().sort_values(ascending=False))\n",
    "print(\"N {:.2f}\".format(df['BERT_neuralmind'].value_counts().sort_values(ascending=False)[0]/df['BERT_neuralmind'].value_counts().sort_values(ascending=False).sum()))\n",
    "print(\"N {:.2f}\".format(df['BERT_neuralmind'].value_counts().sort_values(ascending=False)[1]/df['BERT_neuralmind'].value_counts().sort_values(ascending=False).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.BERT_neuralmind == 'C'][['usuario','tweet','retweets']].sort_values(by = 'retweets', ascending=False).head(5)['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BERT_neuralmind'].to_pickle('dados\\\\df_BERT_neuralmind.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
